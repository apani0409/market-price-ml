{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc231a9",
   "metadata": {},
   "source": [
    "# Agricultural Market Price Prediction\n",
    "## Production-Ready ML Pipeline\n",
    "\n",
    "This notebook demonstrates a complete ML pipeline for predicting agricultural market prices using time-series regression models.\n",
    "\n",
    "**Key Features:**\n",
    "- Time-series data aggregation and feature engineering\n",
    "- Chronological train/test split (no data leakage)\n",
    "- RandomForest vs LinearRegression comparison\n",
    "- Production-quality code using modular functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c2bfe",
   "metadata": {},
   "source": [
    "## 1. Load and Parse Data\n",
    "\n",
    "Load the CSV file using pandas and parse the `publication_date` column as datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, str(Path('.').resolve()))\n",
    "\n",
    "from src.data_loader import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960e137",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Filtering\n",
    "\n",
    "Remove rows with missing price or variety, and filter to keep only kg units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8390f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import clean_data\n",
    "\n",
    "initial_rows = len(df)\n",
    "df_clean = clean_data(df)\n",
    "removed_rows = initial_rows - len(df_clean)\n",
    "\n",
    "print(f\"Initial rows: {initial_rows}\")\n",
    "print(f\"Final rows: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {removed_rows} ({100*removed_rows/initial_rows:.1f}%)\")\n",
    "\n",
    "print(\"\\nUnique units remaining:\")\n",
    "print(df_clean['unit'].unique())\n",
    "\n",
    "print(\"\\nNumber of unique products (varieties):\")\n",
    "print(df_clean['variety'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8ff73",
   "metadata": {},
   "source": [
    "## 3. Aggregate Data by Product and Time Period\n",
    "\n",
    "Group data by (variety, year, week) to calculate mean price and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9baf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import aggregate_weekly\n",
    "\n",
    "df_agg = aggregate_weekly(df_clean)\n",
    "\n",
    "print(f\"Aggregated dataset shape: {df_agg.shape}\")\n",
    "print(f\"\\nUnique (variety, year, week) combinations: {len(df_agg)}\")\n",
    "\n",
    "print(\"\\nSample aggregated data:\")\n",
    "display(df_agg.head(10))\n",
    "\n",
    "print(\"\\nMean price statistics:\")\n",
    "print(df_agg['mean_price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c014bb",
   "metadata": {},
   "source": [
    "## 4. Create Time-Based Features\n",
    "\n",
    "Add week_of_year and rolling statistics (4-week window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import feature_engineering_pipeline\n",
    "\n",
    "df_features = feature_engineering_pipeline(df_agg, rolling_window=4)\n",
    "\n",
    "print(f\"Features created. Dataset shape: {df_features.shape}\")\n",
    "print(f\"\\nColumns: {df_features.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nSample with engineered features:\")\n",
    "display(df_features[['variety', 'year', 'week', 'mean_price', \n",
    "                     'week_of_year', 'rolling_mean_price', 'rolling_std_price']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72567856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify features for a single product\n",
    "sample_variety = df_features['variety'].iloc[0]\n",
    "sample_data = df_features[df_features['variety'] == sample_variety].head(10)\n",
    "\n",
    "print(f\"Example: {sample_variety}\")\n",
    "print(\"\\nPrice and rolling statistics over time:\")\n",
    "display(sample_data[['year', 'week', 'mean_price', 'rolling_mean_price', 'rolling_std_price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bad4ce",
   "metadata": {},
   "source": [
    "## 5. Prepare Training and Test Sets with Time-Aware Split\n",
    "\n",
    "Split data chronologically without shuffling to preserve temporal order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import time_aware_split, prepare_features\n",
    "\n",
    "# Time-aware split: 80% train, 20% test\n",
    "train_df, test_df = time_aware_split(df_features, test_size=0.2)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(f\"Total: {len(train_df) + len(test_df)} samples\")\n",
    "\n",
    "# Get features and target\n",
    "X_train, y_train = prepare_features(train_df)\n",
    "X_test, y_test = prepare_features(test_df)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_train.shape}\")\n",
    "print(f\"Target vector shape: {y_train.shape}\")\n",
    "\n",
    "# Check temporal ordering\n",
    "print(\"\\nTemporal ordering check:\")\n",
    "print(f\"Train set date range: {train_df['publication_date'].min()} to {train_df['publication_date'].max()}\")\n",
    "print(f\"Test set date range: {test_df['publication_date'].min()} to {test_df['publication_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2c19c",
   "metadata": {},
   "source": [
    "## 6. Train Regression Models\n",
    "\n",
    "Train RandomForest and LinearRegression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import train_model\n",
    "\n",
    "# Train RandomForest\n",
    "print(\"Training RandomForestRegressor...\")\n",
    "rf_model = train_model(X_train, y_train, model_type='random_forest')\n",
    "print(\"✓ RandomForest training complete\")\n",
    "\n",
    "# Train LinearRegression\n",
    "print(\"\\nTraining LinearRegression...\")\n",
    "lr_model = train_model(X_train, y_train, model_type='linear_regression')\n",
    "print(\"✓ LinearRegression training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8eec1",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance\n",
    "\n",
    "Evaluate both models using MAE and RMSE metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import evaluate_model\n",
    "\n",
    "# Evaluate RandomForest\n",
    "print(\"Evaluating RandomForestRegressor...\")\n",
    "rf_results = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "print(f\"  MAE:  {rf_results['mae']:.4f}\")\n",
    "print(f\"  RMSE: {rf_results['rmse']:.4f}\")\n",
    "\n",
    "# Evaluate LinearRegression\n",
    "print(\"\\nEvaluating LinearRegression...\")\n",
    "lr_results = evaluate_model(lr_model, X_test, y_test)\n",
    "\n",
    "print(f\"  MAE:  {lr_results['mae']:.4f}\")\n",
    "print(f\"  RMSE: {lr_results['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee49c6f",
   "metadata": {},
   "source": [
    "## 8. Model Comparison and Results\n",
    "\n",
    "Compare model performance and visualize predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['RandomForest', 'LinearRegression'],\n",
    "    'MAE': [rf_results['mae'], lr_results['mae']],\n",
    "    'RMSE': [rf_results['rmse'], lr_results['rmse']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "display(comparison)\n",
    "\n",
    "# Determine best model\n",
    "best_model = 'RandomForest' if rf_results['mae'] < lr_results['mae'] else 'LinearRegression'\n",
    "print(f\"\\n✓ Best model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a22e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: MAE Comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.bar(comparison['Model'], comparison['MAE'], color=['#1f77b4', '#ff7f0e'], alpha=0.8)\n",
    "ax1.set_ylabel('Mean Absolute Error', fontsize=12)\n",
    "ax1.set_title('MAE Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(comparison['MAE']):\n",
    "    ax1.text(i, v + 2, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Plot: RMSE Comparison\n",
    "ax2.bar(comparison['Model'], comparison['RMSE'], color=['#1f77b4', '#ff7f0e'], alpha=0.8)\n",
    "ax2.set_ylabel('Root Mean Squared Error', fontsize=12)\n",
    "ax2.set_title('RMSE Comparison', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(comparison['RMSE']):\n",
    "    ax2.text(i, v + 3, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Actual vs Predicted (Best Model)\n",
    "if best_model == 'RandomForest':\n",
    "    predictions = rf_results['predictions']\n",
    "else:\n",
    "    predictions = lr_results['predictions']\n",
    "\n",
    "actuals = rf_results['actuals']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(actuals, predictions, alpha=0.5, s=30, color='#1f77b4')\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(actuals.min(), predictions.min())\n",
    "max_val = max(actuals.max(), predictions.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "ax.set_xlabel('Actual Price', fontsize=12)\n",
    "ax.set_ylabel('Predicted Price', fontsize=12)\n",
    "ax.set_title(f'{best_model}: Actual vs Predicted Prices', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction errors\n",
    "errors = actuals - predictions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(errors, bins=50, color='#1f77b4', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax.axvline(x=errors.mean(), color='g', linestyle='-', linewidth=2, label=f'Mean Error: {errors.mean():.2f}')\n",
    "ax.set_xlabel('Prediction Error (Actual - Predicted)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('Distribution of Prediction Errors', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Error Statistics:\")\n",
    "print(f\"  Mean:   {errors.mean():.4f}\")\n",
    "print(f\"  Std:    {errors.std():.4f}\")\n",
    "print(f\"  Min:    {errors.min():.4f}\")\n",
    "print(f\"  Max:    {errors.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions from test set\n",
    "test_results = test_df.copy()\n",
    "test_results['predicted_price'] = predictions\n",
    "\n",
    "print(\"Sample Predictions (first 10 test samples):\")\n",
    "display(test_results[['variety', 'year', 'week', 'mean_price', 'predicted_price']].head(10))\n",
    "\n",
    "# Calculate MAPE for reference\n",
    "mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100\n",
    "print(f\"\\nMean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914b4ae",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Data Processing**\n",
    "   - Successfully loaded and cleaned 9,184 raw records\n",
    "   - Filtered to 5,075 kg-based records across multiple agricultural products\n",
    "   - Aggregated into 4,509 unique (variety, year, week) combinations\n",
    "\n",
    "2. **Feature Engineering**\n",
    "   - Created temporal features: week_of_year\n",
    "   - Computed rolling statistics: 4-week rolling mean and std\n",
    "   - Final feature set: 5 predictive features\n",
    "\n",
    "3. **Model Performance**\n",
    "   - Time-aware split ensures no temporal leakage\n",
    "   - RandomForest typically outperforms LinearRegression for non-linear price patterns\n",
    "   - MAE indicates average prediction error in price units\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "✓ **Production Use**: Use the modular code in `src/` for reproducibility\n",
    "✓ **Hyperparameter Tuning**: Experiment with rolling window sizes and model parameters\n",
    "✓ **Feature Expansion**: Consider adding seasonal features, lag features, or external data\n",
    "✓ **Cross-Validation**: Implement time-series cross-validation for robust evaluation\n",
    "✓ **Model Persistence**: Save trained models for deployment\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Deploy the best model to production using the modular pipeline\n",
    "2. Set up monitoring for model performance over time\n",
    "3. Retrain periodically with new data\n",
    "4. Investigate high-error predictions for specific products"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
